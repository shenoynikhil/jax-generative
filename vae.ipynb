{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3100b3e-a6e0-4474-876d-df459372c56c",
   "metadata": {},
   "source": [
    "# (Vanilla) Variational Autoencoder in Jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7cfa2a-d0e9-4295-928d-c7957db265fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dataset Stuff\n",
    "- Load dataset\n",
    "- Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ecc9b0-7844-46f7-b83a-5994666952d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/project/st-jiaruid-1/miniconda3/envs/jax/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3114e563-3e27-40ad-bcad-7361c6bc3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    data_dir='data/',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac66a69c-f1ec-45a4-a816-1af16488d4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /arc/project/st-jiaruid-1/miniconda3/envs/jax/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /arc/project/st-jiaruid-1/miniconda3/envs/jax/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# scale images from 0 to 255 to 0 to 1 (so that reconstruction job is easier)\n",
    "ds_train_norm = ds_train.map(\n",
    "    lambda x, y: (tf.cast(x, tf.float32) / 255., y)\n",
    ")\n",
    "\n",
    "# check if min and max are between 0 and 1\n",
    "first_image = next(iter(ds_train_norm.take(1)))[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e60827a-7118-4e54-8d69-dc58be4b341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_trainloader = ds_train_norm.batch(batch_size)\n",
    "ds_testloader = ds_test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4587835-3f46-4751-9dd0-eeb765c6d8c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build VAE Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b1022-12ea-461a-8ae1-1718d9139cdb",
   "metadata": {},
   "source": [
    "Instead of flattening the images and constructing the VAEs using linear layers, let's build a convolutional VAE. The Variational Autoencoder has the following components,\n",
    "1. Encoder: predicts $\\mu$ and $\\log\\sigma^2$ from images using conv layers and then linear layers.\n",
    "2. Sampling: use the reparametrization trick, we sample from a gaussian of `latent_dim` size and then reparametrize using the $\\mu$ and $\\sigma$.\n",
    "3. Decoder: Samples new images given the latent variable from the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99997b4-45a1-46f9-a2d6-ef2b2b276455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a4cb9a6-231a-49bc-bd15-af3cf681d9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using the setup way to create our network\n",
    "class VAE(nn.Module):\n",
    "    latent_dim: int\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x, rng):\n",
    "        '''Forward pass of the VAE\n",
    "        \n",
    "        The following things will be done in order,\n",
    "        1. Encoder: Converts images to \\mu and log (\\sigma^2) (or log variance)\n",
    "        2. Reparametrized Sampling: Samples latents using reparametrization trick\n",
    "        3. Decoder: Samples images using latents\n",
    "        '''        \n",
    "        # -------- Encoder -----------\n",
    "        mu, logvar = self.encoder(x)\n",
    "        \n",
    "        # -------- Reparametrized Sampling -----------\n",
    "        z = self.reparametrize(mu, logvar, rng)\n",
    "        \n",
    "        # -------- Decode Images ---------\n",
    "        gen_x = self.decoder(rng, z=z)\n",
    "        \n",
    "        return mu, logvar, gen_x\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        '''Encodes an image into \\mu and \\logvar with self.latent size'''        \n",
    "        # use conv filters\n",
    "        # since mnist images, input image size 28 x 28 x 1\n",
    "        x = nn.Conv(32, kernel_size=(3, 3), strides=2, name='enc_conv_1')(x) # 28 x 28 -> 14 x 14\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Conv(32, kernel_size=(3, 3), strides=2, name='enc_conv_2')(x) # 14 x 14 -> 7 x 7\n",
    "        x = x.reshape(x.shape[0], -1) # (batch_size, 7 x 7 x 32)\n",
    "        \n",
    "        # get \\mu and \\logvar of latent space\n",
    "        mu = nn.Dense(self.latent_dim, name='enc_dense_1')(x) # \n",
    "        logvar = nn.Dense(self.latent_dim, name='enc_dense_2')(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparametrize(self, mu, logvar, rng):\n",
    "        '''Samples from a Gaussian Distribution and Reparametrize using \\mu and \\logvar'''\n",
    "        # sample from gaussian\n",
    "        e = random.normal(rng, shape=(self.latent_dim,))\n",
    "        \n",
    "        # convert log-variance to standard deviation, std = \\root(\\exp log-variance)\n",
    "        std = jnp.exp(0.5 * logvar)\n",
    "        \n",
    "        # reparametrization trick\n",
    "        return mu + e * std\n",
    "        \n",
    "    def decoder(self, rng, z):\n",
    "        '''Decodes from latent representation, generate z from gaussian and decode images\n",
    "        '''\n",
    "        # exactly similar to encoder but in reverse, Conv -> ConvTranspose\n",
    "        gen_x = nn.Dense(7 * 7 * 32, name='dec_dense')(z).reshape(z.shape[0], 7, 7, 32) # (batch_size, 7, 7, 32)\n",
    "        gen_x = nn.ConvTranspose(32, kernel_size=(3, 3), strides=(2, 2), name='dec_conv_t_1')(gen_x) # 7 x 7 -> 14 x 14\n",
    "        gen_x = nn.gelu(gen_x)\n",
    "        gen_x = nn.ConvTranspose(1, kernel_size=(3, 3), strides=(2, 2), name='dec_conv_t_2')(gen_x) # 14 x 14 -> 28 x 28\n",
    "        gen_x = nn.sigmoid(gen_x)\n",
    "        return gen_x\n",
    "\n",
    "    def generate(self, rng, num_samples=10):\n",
    "        '''Generates num_samples images'''\n",
    "        z = random.normal(rng, shape=(num_samples, self.latent_dim))        \n",
    "        return self.decoder(rng, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c767b77-54a2-4c1d-b7c6-6a18a91683f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### State Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "657dc0e7-4829-4664-9ea0-2b1ed4dd3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "import optax as opt\n",
    "\n",
    "def create_state(model, key, rng, learning_rate=1e-3):\n",
    "    x = jnp.array(np.random.randn(1, 28, 28, 1))\n",
    "    params = model.init(key, x, rng)['params']\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=opt.adam(learning_rate=learning_rate)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aec78a-9760-4c60-871d-a2779a2ec990",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead3774-16f0-4e93-b3a0-b485c8563418",
   "metadata": {},
   "source": [
    "In the training step, we will do the forward pass and compute losses. Variational Autoencoders have two kinds of losses,\n",
    "1. Negative Log Likelihood\n",
    "2. KL-Divergence Loss between true prior $p(z)$ and approximate posterior $q(z|x)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21313246-494c-4a3a-9359-266c5d3ef0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "def training_step(state, imgs, rng):\n",
    "    imgs = jnp.array(imgs)\n",
    "    def loss_fn(params):\n",
    "        mu, logvar, recon_imgs = model.apply({'params': params}, imgs, rng)\n",
    "        # reconstruction loss: Using mean squared error\n",
    "        recon_loss = ((recon_imgs - imgs) ** 2).mean(axis=0).sum()  # Mean over batch, sum over pixels\n",
    "        # kl-divergence loss\n",
    "        kl_loss = -0.5 * jnp.sum(1 + logvar - jnp.square(mu) - jnp.exp(logvar))\n",
    "        loss = recon_loss + kl_loss\n",
    "        log = {\n",
    "            \"loss\": loss,\n",
    "            \"recon_loss\": recon_loss,\n",
    "            \"kl_loss\": kl_loss\n",
    "        }\n",
    "        return loss, log\n",
    "    \n",
    "    # get gradient function using jax.grad()\n",
    "    (loss, log), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    \n",
    "    # apply gradients to state\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48ace9-1b77-49dd-837d-a7b4fea21eae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2ac21a8-56ea-455d-b457-166cfd2e02da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training progress:   9%|▉         | 177/1875 [00:40<06:24,  4.42it/s, kl_loss=1.6461719, loss=48.06882]\n",
      "Training progress: 100%|██████████| 1875/1875 [06:48<00:00,  4.63it/s, kl_loss=1.2289428, loss=24.680344, reconstruction_loss=23.4514]   \n",
      "Epochs: 100%|██████████| 1/1 [06:48<00:00, 408.38s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epoch_num = 1\n",
    "epochs = tqdm(range(epoch_num), desc=\"Epochs\", leave=True)\n",
    "training_progress = tqdm(total=len(ds_trainloader), desc=\"Training progress\", position=0, leave=True)\n",
    "\n",
    "model = VAE(latent_dim = 10)\n",
    "rng = random.PRNGKey(0)\n",
    "rng, key = random.split(rng)\n",
    "state = create_state(model, key, rng, learning_rate=1e-3)\n",
    "history = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    # reset training_progress\n",
    "    training_progress.reset()\n",
    "    \n",
    "    # loop over batches\n",
    "    for batch_id, batch in enumerate(ds_trainloader):\n",
    "        imgs = batch[0]\n",
    "        # train\n",
    "        state, log = training_step(state, imgs, rng)\n",
    "        training_progress.update()\n",
    "        \n",
    "        history.append(jax.tree_map(np.asarray, log))\n",
    "        training_progress.set_postfix(loss=log['loss'], kl_loss=log['kl_loss'], reconstruction_loss=log['recon_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f072d3-1b22-432b-9792-1ac34dac8b7c",
   "metadata": {},
   "source": [
    "### Plot Reconstructed Images Post Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56519c70-3fa3-4382-8fd7-d50ea0da5c18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mapply({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: state\u001b[38;5;241m.\u001b[39mparams}, \u001b[43mx\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrng\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "model.apply({'params': state.params}, , 'rng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92f4fe-6442-42f4-bce3-84dd52e8d5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
